{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNThEb8h7Yt16MWIaiWurgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badrilosaberidze/Facial-expression-recognition-challenge/blob/main/Model_Experiment_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Login into wandb And essential imports"
      ],
      "metadata": {
        "id": "Pj-o1A7B0FmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "4xEszZ4zzWhf",
        "outputId": "278661cc-c6c4-4a39-af2c-65745334213d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mblosa22\u001b[0m (\u001b[33mblosa22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250607_172923-tdftmvkk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition/runs/tdftmvkk' target=\"_blank\">deeper-cnn-dropout0.3-LRDecay</a></strong> to <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition/runs/tdftmvkk' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition/runs/tdftmvkk</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -q wandb\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "wandb.init(project=\"facial-expression-recognition\", config={\n",
        "    \"epochs\": 15,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 1e-3,\n",
        "    \"architecture\": \"SimpleCNN\"\n",
        "}, name = 'deeper-cnn-dropout0.3-LRDecay')\n",
        "config = wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount to drive and downlaod dataset"
      ],
      "metadata": {
        "id": "N-lA9ivV4eT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC9py3b033qE",
        "outputId": "5cc7d86a-cb03-4440-b9b4-4d4d3d9b24bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset\n",
        "!kaggle competitions download -c challengeas-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_KesxPr4Ohh",
        "outputId": "7387fedb-a5ed-43ec-b024-5d74aae22c4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/data/download-all/challengeas-in-representation-learning-facial-expression-recognition-challenge\n",
            "replace example_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace example_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2_0wCh8NKY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Data And Preproccessing"
      ],
      "metadata": {
        "id": "Lp6YypX_6swY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.images = dataframe['pixels'].apply(lambda x: np.array(x.split(), dtype='float32').reshape(48, 48))\n",
        "        self.labels = dataframe['emotion'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.fromarray(self.images.iloc[idx]).convert(\"L\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "## this was for augmentation , which in fact didnt worked really well\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(48, scale=(0.9, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "#dataset = FERDataset(\"train.csv\", transform=transform)\n",
        "#train_size = int(0.8 * len(dataset))\n",
        "#val_size = len(dataset) - train_size\n",
        "#train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "#train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "#val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n"
      ],
      "metadata": {
        "id": "Jaita7TY4v6S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['emotion'])\n",
        "\n",
        "train_ds = FERDataset(train_df, transform=val_transform)\n",
        "val_ds = FERDataset(val_df, transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n"
      ],
      "metadata": {
        "id": "lJQPtolgSSRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base CNN"
      ],
      "metadata": {
        "id": "rDlB-Lou7C4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        import torch.nn as nn\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 3 * 3, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 7)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = SimpleCNN()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUhT6aSW7Aov",
        "outputId": "d82f18de-3c20-4b14-c7df-666a22e36968"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (net): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Dropout(p=0.3, inplace=False)\n",
              "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Dropout(p=0.3, inplace=False)\n",
              "    (16): Flatten(start_dim=1, end_dim=-1)\n",
              "    (17): Linear(in_features=2304, out_features=128, bias=True)\n",
              "    (18): ReLU()\n",
              "    (19): Dropout(p=0.3, inplace=False)\n",
              "    (20): Linear(in_features=128, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train And Log Into wandb"
      ],
      "metadata": {
        "id": "pNOfSZKk7QwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=100)\n",
        "\n",
        "\n",
        "for epoch in range(config.epochs):\n",
        "    model.train()\n",
        "    running_loss, correct = 0.0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_loader.dataset)\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"epoch\": epoch + 1})\n",
        "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5grC06_t7MOd",
        "outputId": "3b7a129e-4427-4ca8-8ad7-bf51fb51c701"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.7861, Acc: 0.2570\n",
            "Epoch 2, Loss: 1.6412, Acc: 0.3542\n",
            "Epoch 3, Loss: 1.5119, Acc: 0.4144\n",
            "Epoch 4, Loss: 1.4287, Acc: 0.4494\n",
            "Epoch 5, Loss: 1.3691, Acc: 0.4698\n",
            "Epoch 6, Loss: 1.3150, Acc: 0.4991\n",
            "Epoch 7, Loss: 1.2872, Acc: 0.5090\n",
            "Epoch 8, Loss: 1.2580, Acc: 0.5194\n",
            "Epoch 9, Loss: 1.2410, Acc: 0.5231\n",
            "Epoch 10, Loss: 1.2244, Acc: 0.5343\n",
            "Epoch 11, Loss: 1.1895, Acc: 0.5460\n",
            "Epoch 12, Loss: 1.1817, Acc: 0.5493\n",
            "Epoch 13, Loss: 1.1691, Acc: 0.5537\n",
            "Epoch 14, Loss: 1.1566, Acc: 0.5638\n",
            "Epoch 15, Loss: 1.1472, Acc: 0.5659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "val_loss, val_correct = 0.0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        val_correct += (preds == labels).sum().item()\n",
        "\n",
        "val_loss /= len(val_loader)\n",
        "val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "print(f\"\\nFinal Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "wandb.log({\"val_loss\": val_loss, \"val_acc\": val_acc})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "MFbcM3ZIDVZ7",
        "outputId": "47935e50-b1c8-4922-dee7-caa31d960bc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Validation Accuracy: 0.5775, Validation Loss: 1.1185\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_acc</td><td>0.56586</td></tr><tr><td>train_loss</td><td>1.14717</td></tr><tr><td>val_acc</td><td>0.5775</td></tr><tr><td>val_loss</td><td>1.11852</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">deeper-cnn-dropout0.3-LRDecay</strong> at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition/runs/tdftmvkk' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition/runs/tdftmvkk</a><br> View project at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250607_172923-tdftmvkk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7G1-kCCFeB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}